# -*- coding: utf-8 -*-
"""Image Classification Deployment_Rahmat Pratami.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J80aMbWDPG6jX78GpH6UH6Xwr18v57dp

<p>Nama: Rahmat Pratami</p>
  <p>Email: exzaardyansyah894@gmail.com</p>
"""

!pip install split_folders tqdm

!pip install -q kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

!chmod 600 /root/.kaggle/kaggle.json
!kaggle datasets download -d madisona/translated-animals10

# Create new Directory
!mkdir datapict
!unzip -qq translated-animals10.zip -d datapict
!ls datapict

# Import Directory

import tensorflow as tf
import shutil
import splitfolders
import os
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import random
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications import ResNet152V2
from tensorflow.keras.layers import Input

print(tf.__version__)

# Delete Directory

shutil.rmtree('datapict/animals10/raw-img/butterfly')
shutil.rmtree('datapict/animals10/raw-img/chicken')
shutil.rmtree('datapict/animals10/raw-img/horse')
shutil.rmtree('datapict/animals10/raw-img/elephant')
shutil.rmtree('datapict/animals10/raw-img/spider')
shutil.rmtree('datapict/animals10/raw-img/squirrel')

splitfolders.ratio('datapict/animals10/raw-img/', output = 'datapict/animals10/raw-img/animal', ratio = (0.8, 0.2))

# Join Directory
base_dir = 'datapict/animals10/raw-img/animal'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'val')

train_sheep_dir = os.path.join(train_dir, 'sheep')
train_cow_dir = os.path.join(train_dir, 'cow')
train_dog_dir = os.path.join(train_dir, 'dog')
train_cat_dir = os.path.join(train_dir, 'cat')

validation_sheep_dir = os.path.join(validation_dir, 'sheep')
validation_dog_dir = os.path.join(validation_dir, 'cow')
validation_cow_dir = os.path.join(validation_dir, 'dog')
validation_cat_dir = os.path.join(validation_dir, 'cat')

sheep_files = os.listdir(train_sheep_dir)
cow_files = os.listdir(train_cow_dir)
dog_files = os.listdir(train_dog_dir)
cat_files = os.listdir(train_cat_dir)

pic_index = random.randrange(0, 1000)

image_sheep = [os.path.join(train_sheep_dir, fname) for fname in sheep_files[pic_index-1:pic_index]]
image_cow = [os.path.join(train_cow_dir, fname) for fname in cow_files[pic_index-1:pic_index]]
image_dog = [os.path.join(train_dog_dir, fname) for fname in dog_files[pic_index-1:pic_index]]
image_cat = [os.path.join(train_cat_dir, fname) for fname in cat_files[pic_index-1:pic_index]]

for i, img_path in enumerate(image_sheep + image_cow + image_dog + image_cat):
    img = mpimg.imread(img_path)
    plt.imshow(img)
    plt.axis('Off')
    plt.show()

train_datagen = ImageDataGenerator(rescale = 1./255,
                                   rotation_range = 20,
                                   width_shift_range = 0.2,
                                   height_shift_range = 0.2,
                                   zoom_range = 0.2,
                                   horizontal_flip = True,
                                   vertical_flip=True,
                                   shear_range = 0.2,
                                   fill_mode = 'nearest')

test_datagen = ImageDataGenerator(rescale = 1./255,
                                  rotation_range = 20,
                                  width_shift_range = 0.2,
                                  height_shift_range = 0.2,
                                  zoom_range = 0.2,
                                  horizontal_flip = True,
                                  vertical_flip=True,
                                  shear_range = 0.2,
                                  fill_mode = 'nearest')

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size = (150, 150),  # Change the resolution pixel to 150x150
    batch_size = 64,
    shuffle=False,
    class_mode = 'categorical')

validation_generator = test_datagen.flow_from_directory(
    validation_dir,
    target_size = (150, 150), # Change the resolution pixel to 150x150
    batch_size = 64,
    shuffle=False,
    class_mode = 'categorical')

# Load the VGG16 model but exclude the top layers
base_model = ResNet152V2(weights='imagenet', include_top=False, input_shape=(150, 150, 3))

# Make the base model untrainable
for layer in base_model.layers:
    layer.trainable = False

model = tf.keras.models.Sequential([
    base_model,

    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),  # Use padding='same'
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),  # Use padding='same'
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),  # Use padding='same'

    tf.keras.layers.Flatten(),

    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dropout(0.5),

    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.5),

    tf.keras.layers.Dense(4, activation='softmax')
])

model.summary()

# Callback function to avoid overfit
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs = {}):
    if(logs.get('accuracy') > 0.92 and logs.get('val_accuracy') > 0.92):
      print("\nAkurasi diatas 92%, training selesai!")
      self.model.stop_training = True

callbacks = myCallback()

# Set learning rate
custom_optimizer = Adam(learning_rate=0.00001)

# Compile model with 'Adam' optimizer and categorical cross-entropy loss function

model.compile(optimizer=custom_optimizer,
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(train_generator,
                    epochs = 150,
                    steps_per_epoch=len(train_generator),
                    validation_data = validation_generator,
                    validation_steps=len(validation_generator),
                    verbose = 2,
                    callbacks = [callbacks])

# Plot training & validation accuracy values
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')

# Plot training & validation loss values
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(loc='upper right')

plt.show()

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with tf.io.gfile.GFile('animal.tflite', 'wb') as f:
  f.write(tflite_model)